---
title: "Analyse des données européennes"
author: "FALL Khadim , CALLET Elliot"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    number_sections: true
    toc: true
    latex_engine: xelatex

---

Le code source du projet est disponible sur GitHub :https://github.com/khadimfall2/Analysis.git

Les données analysées dans ce projet concernent différents indicateurs socio-économiques et environnementaux pour un ensemble de pays européens. Ces indicateurs offrent une vision globale de divers aspects comme la démographie, l'économie, l'énergie, l'emploi et l'environnement. Les analyses visent à explorer les structures sous-jacentes et les relations entre ces variables, ainsi qu'à regrouper les pays selon des caractéristiques communes.


*Description des variables*

   Les données contiennent 16 variables descriptives de 30 pays européens , reflétant des dimensions clés : 

   Population au 1er janvier : Nombre absolu d'habitants.
   
   Population jeune (15-29 ans) : Pourcentage de jeunes dans la population totale.
  
   Premières demandes d'asile : Nombre absolu de demandes.
   
  Écart de rémunération entre les sexes : Pourcentage de différence de salaire horaire brut moyen entre hommes et femmes.
    
   Salaire minimum : Montant en euros par mois.
    
   Décrocheurs scolaires précoces : Pourcentage de la population âgée de 18 à 24 ans quittant prématurément le système scolaire.
    
  Taux d'inflation : Variation en pourcentage par rapport à l'année précédente.
    
  Taux de chômage : Pourcentage de la population active âgée de 15 à 74 ans.
    
  Taux de chômage des jeunes : Pourcentage de la population active de moins de 25 ans.
    
   PIB par habitant : Produit intérieur brut en euros par habitant.
    
   Dette brute du gouvernement : Pourcentage de la dette brute par rapport au PIB.
    
  Émissions de gaz à effet de serre : Quantité moyenne en tonnes par habitant.
    
  Énergies renouvelables : Pourcentage dans la consommation finale brute d'énergie.
    
  Prix de l'électricité : Montant en euros par MWh, incluant les taxes.
    
  Dépendance aux importations d'énergie : Pourcentage de dépendance à l'énergie importée.
    
  Taux de risque de pauvreté ou d'exclusion sociale : Pourcentage de la population à risque de pauvreté ou d'exclusion sociale.

L’objectif de cette analyse est d’explorer et de réduire la dimensionnalité des données grâce à une analyse en composantes principales (ACP), puis de grouper les pays selon leurs caractéristiques à l’aide de méthodes de classification. L’ACP permet de visualiser les similitudes entre pays et d’identifier les variables les plus remarquables . Les méthodes de classification, notamment la classification ascendante hiérarchique (CAH) et l’algorithme des centres mobiles (k-means), permettent d’interpréter les regroupements obtenus. Les résultats des classifications seront comparés afin de comprendre les proximités entre pays et leur cohérence.

Pour la préparation des données, une normalisation a été appliquée dans certains cas pour rendre les variables comparables. L’analyse inclut la création de matrices de dissimilarité, l’utilisation de la décomposition en valeurs propres pour l’ACP, et l’application des méthodes de classification sur les données normalisées. Les regroupements obtenus seront interprétés à travers l’étude des centres de gravité, des inerties et des plans factoriels. Enfin, une attention particulière sera portée à l’analyse des proximités des pays dans des zones spécifiques de l’espace factoriel, afin de mieux comprendre les similarités entre pays.








```{r setup, message=FALSE, warning=FALSE}
# Vérification et chargement des bibliothèques nécessaires
if (!require(ggplot2)) install.packages("ggplot2", dependencies = TRUE)
library(ggplot2)

# Chargement de TinyTeX si nécessaire (une seule fois)
if (!tinytex::is_tinytex()) {
  tinytex::install_tinytex()
}
knitr::opts_chunk$set(comment = NA)
```




```{r}
euro_data <- read.csv("data/euro.csv", header = TRUE, sep = ";")

# Normalisation des données (Min-Max Scaling)
euro_data_normalized <- as.data.frame(lapply(euro_data[, -1], function(x) {
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}))

```



*Diagrammes à mmoustache*



```{r}
library(gridExtra)

# Lire les données
euro_data <- read.csv("data/euro.csv", header = TRUE, sep = ";")

# Créer un fichier PDF
pdf("euro_data.pdf", width = 30, height = 20)

# Afficher le tableau des données dans le PDF
grid.table(euro_data)

# Fermer le fichier PDF
dev.off()

```




```{r}
# Supprimer la première colonne contenant les pays.
euro_data <- euro_data[, -1]


selected_columns <- colnames(euro_data)[1:2]  

# Ajuster les marges et l'espacement
par(mfrow = c(1, 2),  # Deux graphiques côte à côte
    oma = c(2, 2, 2, 2),  # Marges extérieures : bas, gauche, haut, droite
    mar = c(5, 5, 4, 2))  # Marges intérieures : bas, gauche, haut, droite

# Boucle pour tracer les boîtes à moustaches
for (col_name in selected_columns) {
  boxplot(euro_data[[col_name]],
          main = paste("Boîte à moustaches\n", col_name),  # Titre sur deux lignes
          ylab = col_name,
          col = "lightblue",
          border = "darkblue",
          cex.main = 1.1,  # Taille du titre
          cex.lab = 1.1,  # Taille des étiquettes
          cex.axis = 0.9)  # Taille des axes
}






```
La distribution de la variable Population montre une grande variabilité entre les pays européens. Certains pays, comme l’Allemagne (84,3 millions), la France (68,1 millions) et l’Italie (58,9 millions), présentent des populations nettement supérieures à la majorité. Ces valeurs extrêmes contrastent avec des pays de petite taille comme Malte (0,54 million) et Chypre (0,92 million). La médiane, bien centrée dans la boîte du boxplot, reflète une répartition relativement équilibrée dans l’intervalle interquartile, bien que la présence de valeurs aberrantes, telles que celles de l’Allemagne et de la France, étende la distribution vers des valeurs élevées.

Quant à la variable Youth Population (pourcentage de jeunes âgés de 15 à 29 ans), elle présente une répartition beaucoup plus homogène. Les pourcentages varient de 13,2 % (Bulgarie) à 21,0 % (Islande), sans aucune valeur aberrante. Cependant, la médiane est située dans le quart inférieur de la boîte du boxplot, ce qui indique que les proportions de jeunes pour la majorité des pays se concentrent légèrement au-dessus de la médiane. On observe que les pays nordiques, comme l’Islande (21,0 %) et la Norvège (18,7 %), possèdent des proportions relativement élevées de jeunes, tandis que des pays comme la Bulgarie se situent à l’extrémité inférieure de cette répartition.


```{r}

selected_columns <- colnames(euro_data)[3:4]  


par(mfrow = c(1, 2),  
    oma = c(2, 2, 2, 2),  
    mar = c(5, 5, 4, 2))  


for (col_name in selected_columns) {
  boxplot(euro_data[[col_name]],
          main = paste("Boîte à moustaches\n", col_name),  
          ylab = col_name,
          col = "lightblue",
          border = "darkblue",
          cex.main = 1.2,  
          cex.lab = 1.1,  
          cex.axis = 0.9)  
}


```
La distribution de la variable First Time Asylum Applicants (premières demandes d’asile) montre une forte asymétrie, avec plusieurs valeurs extrêmes très élevées. Ces valeurs, représentées par des points au-dessus des moustaches, indiquent que quelques pays reçoivent un nombre disproportionné de premières demandes d’asile par rapport à la majorité. La médiane basse reflète que la moitié des pays ont un faible nombre de demandes d’asile, tandis que les valeurs élevées sont concentrées dans un petit nombre de pays, ce qui étend la moustache supérieure.

La variable Gender Pay Gap (écart de rémunération entre les sexes) présente une distribution symétrique et homogène. La médiane est bien centrée, et la boîte à moustaches indique que les valeurs sont concentrées dans une plage relativement étroite. Aucun outlier n’est visible, ce qui suggère que les écarts salariaux entre les sexes sont globalement similaires parmi les pays analysés.
Interprétation

Les données brutes confirment les observations issues des diagrammes à moustaches. Concernant les First Time Asylum Applicants, on observe de fortes valeurs pour des pays comme l'Allemagne (0,32 million) et la France (0,14 million), qui reçoivent un grand nombre de demandes. À l'inverse, des pays comme la Slovaquie (0,0003 million) et la Hongrie (0,00003 million) présentent des valeurs bien en dessous de la moyenne, reflétant une disparité importante.

Pour la variable Gender Pay Gap, les données confirment l'homogénéité observée. Toutefois, on peut noter des différences significatives entre certains pays. Par exemple, l'Autriche (18,4) et la Suisse (17,9) affichent des valeurs élevées, tandis que le Luxembourg présente une valeur négative (-0,7), indiquant une situation inverse inhabituelle.

```{r}

selected_columns <- colnames(euro_data)[5:6]  

par(mfrow = c(1, 2),  
    oma = c(2, 2, 2, 2),  
    mar = c(5, 5, 4, 2))  


for (col_name in selected_columns) {
  boxplot(euro_data[[col_name]],
          main = paste("Boîte à moustaches\n", col_name), 
          ylab = col_name,
          col = "lightblue",
          border = "darkblue",
          cex.main = 1.2,  
          cex.lab = 1.1,  
          cex.axis = 0.9)  
}


```


On remarque que les salaires varient de 500 à 2000 .
La distribution de la variable Minimum Wage (salaire minimum) montre une dispersion modérée avec quelques valeurs basses qui se démarquent, visibles sous forme de moustaches allongées. La médiane, située dans la moitié inférieure de la boîte, indique que la moitié des pays ont un salaire minimum inférieur à cette valeur médiane. Aucune valeur aberrante significative n’est visible, ce qui reflète une relative homogénéité dans la répartition des salaires minimums parmi les pays étudiés.

La variable People at Risk of Poverty or Exclusion (personnes à risque de pauvreté ou d’exclusion sociale) présente une distribution relativement homogène. La médiane, légèrement orientée vers le bas de la boîte, indique que la moitié des pays ont des valeurs proches mais légèrement inférieures à la médiane. La taille modérée de la boîte et l’absence de valeurs aberrantes suggèrent que les pays étudiés affichent des niveaux de risque relativement similaires pour cet indicateur.
```{r}
selected_columns <- colnames(euro_data)[7:8]  


par(mfrow = c(1, 2), 
    oma = c(2, 2, 2, 2),  
    mar = c(5, 5, 4, 2))  


for (col_name in selected_columns) {
  boxplot(euro_data[[col_name]],
          main = paste("Boîte à moustaches\n", col_name), 
          ylab = col_name,
          col = "lightblue",
          border = "darkblue",
          cex.main = 1.2,  
          cex.lab = 1.1, 
          cex.axis = 0.9)  
}

```
Early School Leavers (décrocheurs scolaires précoces) : La distribution de cette variable montre une répartition homogène, sans valeurs aberrantes significatives. La médiane, légèrement orientée vers le bas de la boîte, indique que la moitié des pays ont des taux de décrochage scolaire légèrement inférieurs à la médiane. Les moustaches montrent que les taux de décrochage scolaire sont globalement compris dans une plage relativement étroite, reflétant une faible variabilité entre les pays.

Inflation Rate (taux d’inflation) : Cette variable présente une valeur aberrante notable, représentée par un point au-dessus des moustaches, ce qui indique qu’un ou quelques pays ont un taux d’inflation nettement supérieur à celui des autres. La boîte, asymétrique et légèrement orientée vers le bas, suggère que la majorité des pays ont des taux d’inflation relativement faibles, concentrés dans la moitié inférieure de la plage des données.

```{r}

selected_columns <- colnames(euro_data)[9:10]  


par(mfrow = c(1, 2), 
    oma = c(2, 2, 2, 2),  
    mar = c(5, 5, 4, 2))  


for (col_name in selected_columns) {
  boxplot(euro_data[[col_name]],
          main = paste("Boîte à moustaches\n", col_name),
          ylab = col_name,
          col = "lightblue",
          border = "darkblue",
          cex.main = 1.2,  
          cex.lab = 1.1,  
          cex.axis = 0.9)  
}


```
Unemployment Rate (taux de chômage) : La distribution de cette variable est globalement homogène, bien que deux valeurs aberrantes soient visibles au-dessus des moustaches. Ces valeurs traduisent des taux de chômage exceptionnellement élevés pour certains pays par rapport à la majorité. La médiane, légèrement au-dessus du centre de la boîte, indique que la moitié des pays ont des taux de chômage supérieurs ou égaux à la médiane, tandis que les 50 % inférieurs sont répartis sur une plage plus large, traduisant une légère asymétrie vers les valeurs supérieures

Pour la variable Youth Unemployment Rate (taux de chômage des jeunes), la distribution est plus dispersée, sans valeurs aberrantes. La boîte et les moustaches reflètent une variabilité importante entre les pays, traduisant des disparités régionales marquées. La médiane, située un peu en dessous du centre, indique une distribution légèrement asymétrique.
```{r}

selected_columns <- colnames(euro_data)[11:12]  


par(mfrow = c(1, 2),  
    oma = c(2, 2, 2, 2),
    mar = c(5, 5, 4, 2))  


for (col_name in selected_columns) {
  boxplot(euro_data[[col_name]],
          main = paste("Boîte à moustaches\n", col_name),  
          ylab = col_name,
          col = "lightblue",
          border = "darkblue",
          cex.main = 1.2,  
          cex.lab = 1.1,  
          cex.axis = 0.9)
}


```
GDP per Capita (PIB par habitant) : La variable présente une distribution avec une valeur aberrante notable, correspondant à un pays dont le PIB par habitant est extrêmement élevé par rapport aux autres. La majorité des pays se situent dans une plage relativement restreinte, comme le montre la boîte. La médiane, bien centrée dans la boîte, indique une répartition relativement symétrique des valeurs autour de la médiane.

Government Gross Debt (dette brute du gouvernement en pourcentage du PIB) : La variable montre deux valeurs aberrantes au-dessus des moustaches, suggérant que certains pays ont des niveaux de dette exceptionnellement élevés. La médiane, légèrement en dessous du centre de la boîte, reflète une asymétrie vers les valeurs plus faibles, indiquant que les pays ayant des dettes inférieures ou proches de la médiane sont répartis sur une plage plus restreinte, tandis que ceux ayant des dettes supérieures sont davantage dispersés.

```{r}

selected_columns <- colnames(euro_data)[13:14]  


par(mfrow = c(1, 2), 
    oma = c(2, 2, 2, 2), 
    mar = c(5, 5, 4, 2))


for (col_name in selected_columns) {
  boxplot(euro_data[[col_name]],
          main = paste("Boîte à moustaches\n", col_name), 
          ylab = col_name,
          col = "lightblue",
          border = "darkblue",
          cex.main = 1.2,  
          cex.lab = 1.1,  
          cex.axis = 0.9)  
}


```
Greenhouse Gas Emissions (émissions de gaz à effet de serre)
La variable présente deux valeurs aberrantes correspondant à des pays avec des émissions particulièrement élevées. La médiane, située au centre de la boîte, reflète une répartition relativement équilibrée des données. Cela suggère qu'environ la moitié des pays ont des émissions proches ou inférieures à la médiane, tandis que l'autre moitié a des émissions plus élevées.

Renewable Energy (énergies renouvelables)
La variable montre également deux valeurs aberrantes pour des pays ayant une part particulièrement élevée d'énergies renouvelables. La médiane, située vers le bas de la boîte, indique qu'une proportion importante de pays a des parts d'énergies renouvelables faibles ou proches de cette valeur, tandis que l'autre moitié des pays a des parts plus élevées.

```{r}

selected_columns <- colnames(euro_data)[15:16]  


par(mfrow = c(1, 2),  
    oma = c(2, 2, 2, 2),  
    mar = c(5, 5, 4, 2))  


for (col_name in selected_columns) {
  boxplot(euro_data[[col_name]],
          main = paste("Boîte à moustaches\n", col_name),  
          ylab = col_name,
          col = "lightblue",
          border = "darkblue",
          cex.main = 1.2,  
          cex.lab = 1.1,  
          cex.axis = 0.9)  
}


```

Electricity Prices (Prix de l'électricité) :
La médiane est située dans le quart inférieur de la boîte, indiquant que la moitié des pays ont des prix de l'électricité inférieurs ou égaux à cette valeur médiane. L'absence de valeurs aberrantes reflète une distribution relativement homogène parmi les pays. La position basse de la médiane montre que les prix inférieurs à la médiane sont davantage concentrés, tandis que les prix supérieurs couvrent une plage plus étendue, traduisant une certaine variabilité.

Energy Imports Dependency (Dépendance aux importations d'énergie) :
La médiane est située dans le quart supérieur de la boîte, ce qui signifie que la moitié des pays ont une dépendance énergétique inférieure ou égale à cette valeur. Contrairement à la variable précédente, cette distribution montre également une absence de valeurs aberrantes. La position élevée de la médiane reflète une plus grande dispersion des valeurs inférieures, tandis que les valeurs supérieures à la médiane sont relativement concentrées, indiquant une variabilité marquée dans la dépendance énergétique parmi les pays européens.




Pour apporter davantage de visibilité , nous allons remplacer les noms des variables des colonnes par des valeurs numériques, en nous référant à la légende suivante.

Légende des colonnes :  

"[1]: Population  
[2]: Youth.population  
[3]: First.time.asylum.applicants  
[4]: Gender.pay.gap  
[5]: Minimum.wage  
[6]: People.at.risk.of.poverty.or.exclusion  
[7]: Early.school.leavers  
[8]: Inflation.rate  
[9]: Unemployment.rate  
[10]: Youth.unemployment.rate  
[11]: GDP.per.capita  
[12]: Government.gross.debt  
[13]: Greenhouse.gas.emissions  
[14]: Renewable.energy  
[15]: Electricity.prices  
[16]: Energy.imports.dependency"





```{r}
# Étape 1 : Centrer les données (sans mise à l’échelle)
euro_data_centered <- scale(euro_data, center = TRUE, scale = FALSE)

# Étape 2 : Calculer la matrice de variance-covariance
n <- nrow(euro_data)
V <- (t(euro_data_centered) %*% euro_data_centered) / (n - 1)

# Étape 3 : Ajouter des indices numériques pour les colonnes et lignes
colnames(V) <- paste0("[", seq_len(ncol(V)), "]")
rownames(V) <- colnames(euro_data)

# Étape 4 : Arrondir les valeurs pour une meilleure lisibilité
V <- round(V, 4)

# Étape 5 : Ajuster les paramètres d'affichage pour éviter les retours à la ligne
options(width = 200)

# Étape 6 : Afficher la matrice en quatre parties
cat("Matrice de variance-covariance (indices entre crochets pour les colonnes) :\n")

cat("\nPartie 1 : Colonnes [1] à [4]\n")
print(V[, 1:4], row.names = TRUE, right = FALSE)

cat("\nPartie 2 : Colonnes [5] à [8]\n")
print(V[, 5:8], row.names = TRUE, right = FALSE)

cat("\nPartie 3 : Colonnes [9] à [12]\n")
print(V[, 9:12], row.names = TRUE, right = FALSE)

cat("\nPartie 4 : Colonnes [13] à [16]\n")
print(V[, 13:16], row.names = TRUE, right = FALSE)

```

Légende des colonnes : 


"[1]: Population  
[2]: Youth.population  
[3]: First.time.asylum.applicants  
[4]: Gender.pay.gap  
[5]: Minimum.wage  
[6]: People.at.risk.of.poverty.or.exclusion  
[7]: Early.school.leavers  
[8]: Inflation.rate  
[9]: Unemployment.rate  
[10]: Youth.unemployment.rate  
[11]: GDP.per.capita  
[12]: Government.gross.debt  
[13]: Greenhouse.gas.emissions  
[14]: Renewable.energy  
[15]: Electricity.prices  
[16]: Energy.imports.dependency"




La matrice de variance-covariance V calcule la dispersion des variables ainsi que les relations linéaires entre elles. Les valeurs sur la diagonale principale représentent la variance de chaque variable. Par exemple, la variance de Population est très élevée (4.653257e+14), reflétant une grande dispersion entre les pays, comme cela a été observé dans les diagrammes à moustaches. En revanche, la variance de Gender Pay Gap est beaucoup plus faible (25.6190), confirmant l’homogénéité relative notée précédemment, bien qu'elle reste significative.

Une covariance négative entre Renewable Energy et Energy Imports Dependency (−290.3213) reflète une relation inverse plus marquée : les pays avec une part plus élevée d’énergies renouvelables, comme l’Islande et la Norvège, sont généralement moins dépendants des importations d’énergie.

La matrice V enrichit l’analyse exploratoire initiale en fournissant une quantification précise des dispersions et interactions entre variables. Ces résultats constituent une base solide pour des analyses plus avancées, comme l'analyse en composantes principales (ACP), tout en préparant la transition vers l'étude des relations normalisées via la matrice de corrélation.





```{r}
#3
V_rounded <- round(V, 2)
heatmap(as.matrix(V_rounded), 
        main = "Heatmap  variance-covariance",
        Colv = NA, Rowv = NA,  # Désactive le clustering
        scale = "none",  # Pas de normalisation supplémentaire
        col = heat.colors(10),  # Palette de couleurs
        margins = c(15, 15),  # Ajuster les marges
        labCol = colnames(euro_data),  # Noms originaux des colonnes
        labRow = rownames(V_rounded),  # Noms des lignes
        cexCol = 0.8,  # Taille des labels des colonnes
        cexRow = 0.8)  # Taille des labels des lignes


```


Comme les données ne sont pas normalisées, chaque variable est utilisée avec son échelle propre, ce qui limite la possibilité de faire des interprétations précises quant aux variances et covariances. En effet, des échelles différentes rendent difficile la comparaison directe des intensités entre les variables.

Malgré cela, on peut remarquer que la variable Population se distingue par une coloration plus marquée de sa variance, indiquant une forte variation au sein de cette variable. Les zones blanches représentent des valeurs non définies ou nulles, tandis que pour le reste la couleur rouge ne nous permets  pas de discerner de différences significatives entre les covariances des autres variables.

Bien que cette matrice de variance-covariance fournisse des informations limitées en profondeur, elle reste utile pour donner une vue d'ensemble des relations potentielles entre les variables. Cependant, pour extraire davantage d'informations et permettre des comparaisons cohérentes entre les variables, il est préférable d'utiliser la matrice de corrélation, qui repose sur des données normalisées.





```{r}

```


```{r}

# 4 
# Étape 1 : Calculer la matrice de corrélation
correlation_matrix <- cor(euro_data, use = "complete.obs")

# Étape 2 : Arrondir les valeurs à deux décimales pour une meilleure lisibilité
correlation_matrix_rounded <- round(correlation_matrix, 2)

# Étape 3 : Ajouter des indices numériques pour les colonnes et les lignes
colnames(correlation_matrix_rounded) <- paste0("[", seq_len(ncol(correlation_matrix_rounded)), "]")
rownames(correlation_matrix_rounded) <- paste0("[", seq_len(nrow(correlation_matrix_rounded)), "]")

# Étape 4 : Ajuster les paramètres pour l'affichage
options(width = 180)  # Ajuste la largeur pour afficher toutes les colonnes sans retour à la ligne
cat("Matrice de corrélation (indices pour les lignes et colonnes) :\n")

# Étape 5 : Afficher la matrice sous forme de tableau compact
print(correlation_matrix_rounded, row.names = TRUE, right = FALSE)


```
Légende des colonnes : 


"[1]: Population  
[2]: Youth.population  
[3]: First.time.asylum.applicants  
[4]: Gender.pay.gap  
[5]: Minimum.wage  
[6]: People.at.risk.of.poverty.or.exclusion  
[7]: Early.school.leavers  
[8]: Inflation.rate  
[9]: Unemployment.rate  
[10]: Youth.unemployment.rate  
[11]: GDP.per.capita  
[12]: Government.gross.debt  
[13]: Greenhouse.gas.emissions  
[14]: Renewable.energy  
[15]: Electricity.prices  
[16]: Energy.imports.dependency"



La matrice de corrélation offre une vision normalisée des relations linéaires entre les variables, avec des coefficients compris entre -1 et 1. Une corrélation positive modérée est observée entre Population et Youth Population (r=0.87), indiquant que les pays avec une population élevée tendent à avoir une proportion importante de jeunes.

Une relation négative significative est également visible entre Renewable Energy et Energy Imports Dependency (r=−0.54), confirmant que les pays intégrant davantage d’énergies renouvelables sont généralement moins dépendants des importations énergétiques.

De plus, une corrélation très forte (r=0.87) entre Youth Unemployment Rate et Unemployment Rate montre une relation directe entre ces deux indicateurs. En revanche, certaines variables comme Gender Pay Gap et Minimum Wage (r=−0.05) affichent une corrélation quasi nulle, suggérant une absence de relation linéaire significative. Cette matrice met ainsi en évidence les liens les plus marqués tout en soulignant les variables peu ou pas reliées entre elles.

```{r}
# Transformer la matrice de corrélation en format long
correlation_long <- reshape2::melt(round(correlation_matrix, 2))
```


```{r}
# Heatmap de la matrice de corrélation
ggplot(correlation_long, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), 
                       name = "Corrélation") +
  theme_minimal() +
  labs(title = "Heatmap de la matrice de corrélation",
       x = "Variables",
       y = "Variables") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


La heatmap de la matrice de corrélation illustre les relations linéaires entre les différentes variables. Les couleurs rouges indiquent des corrélations positives élevées, tandis que les teintes bleues traduisent des corrélations négatives significatives. Les zones blanches ou pâles, quant à elles, reflètent des relations faibles ou inexistantes.

Par exemple, on remarque une forte corrélation positive entre Population et First Time Asylum Applicants, suggérant que les pays avec une population élevée attirent davantage de demandes d'asile. De même, une forte corrélation existe entre GDP per Capita et Minimum Wage, montrant que les pays avec un PIB élevé ont tendance à offrir des salaires minimums plus élevés.

Une corrélation négative marquée est visible entre Renewable Energy et Energy Imports Dependency, mettant en évidence l'impact positif des énergies renouvelables sur la réduction de la dépendance énergétique. Cela reflète probablement une autonomie énergétique accrue dans les pays intégrant davantage d’énergies renouvelables.

À l'inverse, certaines variables montrent peu ou pas de corrélation, traduisant une absence de relation linéaire notable. Par exemple, Gender Pay Gap et Minimum Wage, ou encore Electricity Prices et Early School Leavers, n'affichent aucune relation significative, ce qui indique que l'évolution de l'une n'apporte aucune information sur l'autre.

Enfin, ce graphique offre une visualisation claire des relations fortes et faibles entre les variables, facilitant l'identification des interactions les plus significatives pour l’analyse. Il permet également de mettre en lumière les variables qui évoluent de manière indépendante les unes des autres.Ce qui n'était pas possible avec la matrice de variance-covariance 





```{r}
# 5 

euro_data_replace_na <- apply(euro_data, 2, function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))
```


```{r}
# 5.
# Calculer les composantes principales
res <- prcomp(euro_data_replace_na, scale = TRUE, center = TRUE)

# Créer un fichier PDF pour les résultats
pdf("resultats_prcomp.pdf", width = 10, height = 8)

# Vérification de l'orthogonalité et des normes
cat("Produit scalaire des vecteurs propres (orthogonalité) :\n")
orthogonality_check <- t(res$rotation) %*% res$rotation
print(round(orthogonality_check, 2))

cat("Normes des vecteurs propres (1 attendu) :\n")
norms <- apply(res$rotation, 2, function(col) sqrt(sum(col^2)))
print(round(norms, 2))

# Afficher les premières coordonnées dans la nouvelle base (divisé en deux parties)
cat("\nPremières coordonnées des observations (Colonnes [1] à [8]) :\n")
print(head(res$x[, 1:8], n = 6))  # Affichage des colonnes 1 à 8

cat("\nPremières coordonnées des observations (Colonnes [9] à [16]) :\n")
print(head(res$x[, 9:16], n = 6))  # Affichage des colonnes 9 à 16

# Ajouter le biplot au PDF
#biplot(res, scale = 0, main = "Biplot des composantes principales")

# Fermer le fichier PDF
#dev.off()

```



Les composantes principales forment une base orthonormée, ce qui est prouvé numériquement. Le produit scalaire des vecteurs propres (matrice de rotation transposée multipliée par elle-même) donne une matrice diagonale avec des valeurs de 1 sur la diagonale et 0 ailleurs, confirmant leur orthogonalité. Les normes des vecteurs propres, calculées comme la racine carrée de la somme des carrés des coefficients, sont toutes égales à 1, prouvant qu'ils sont normalisés.

Le paramètre center = TRUE recentre chaque variable en soustrayant sa moyenne, garantissant que les composantes principales sont calculées par rapport à un centre des données égal à zéro. Le paramètre scale = TRUE met chaque variable à l'échelle en divisant par son écart type, standardisant ainsi les variables pour qu'elles aient toutes une variance de 1, ce qui est crucial lorsque les variables ont des échelles différentes.

Sans center, les composantes principales seraient biaisées par des variables aux moyennes élevées, faussant leur interprétation. Sans scale, les variables avec des échelles ou des variances élevées domineraient les calculs, influençant de manière disproportionnée les composantes principales. En combinant center et scale, chaque variable contribue de manière équitable à la définition des composantes principales.




```{r}
#6 
# Étape 1 : Calculer les composantes principales (si non déjà fait)
euro_data_replace_na <- apply(euro_data, 2, function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))
res <- prcomp(euro_data_replace_na, scale = TRUE, center = TRUE)

```


```{r fig.width=10, fig.height=8}

#6.
coord <- res$x

# Étape 3 : Ajouter les noms des pays comme noms de lignes
tmp <- read.csv("data/euro.csv", header = TRUE, sep = ";")
rownames(coord) <- tmp[, 1]

# Étape 4 : Créer le graphique du premier plan factoriel
plot(coord[, 1], coord[, 2], 
     xlab = "PC1", ylab = "PC2", 
     main = "Premier plan factoriel (PC1 vs PC2)", 
     pch = 20, col = "blue")

# Étape 5 : Ajouter les noms des pays sur le graphique
text(coord[, 1], coord[, 2], labels = rownames(coord), pos = 4, cex = 0.6)
```
Le graphique du premier plan factoriel (PC1 vs PC2) illustre la position relative des pays selon les deux premières composantes principales, qui capturent la majorité de la variance des données. Ces composantes principales permettent de résumer l’ensemble des variables tout en conservant au mieux l’information.

On observe une forte opposition sur l’axe 1 entre des pays comme la France et la République tchèque (Czechia). Cette opposition reflète d’importantes dissimilitudes entre ces deux pays, le premier axe représentant le maximum de variance des données. De manière similaire, l’Allemagne se situe en bas à droite et contraste fortement avec des pays comme la Bulgarie et la Hongrie, positionnés en haut à gauche, traduisant des différences marquées entre ces pays.

Sur l’axe 2, le Luxembourg et la Roumanie occupent des positions opposées, indiquant également une forte dissimilarité entre eux sur les variables résumées par cette composante. Cet axe capture une partie supplémentaire de la variance non expliquée par le premier, apportant une nouvelle perspective dans l’analyse.

Des regroupements centraux sont également visibles, formant un cluster de pays comme le Portugal, la Slovénie, la Suède et Malte. Cette proximité traduit une certaine similarité entre ces pays, du point de vue de l’ensemble des variables étudiées.

Par ailleurs, certains pays se distinguent nettement par leur éloignement des autres :

La Norvège et l’Islande se démarquent dans la partie supérieure droite, probablement en raison de leur indépendance énergétique et de leur forte part d’énergies renouvelables.
À l’opposé, la Grèce, l’Espagne et l’Italie apparaissent isolées dans la partie inférieure gauche, ce qui peut s’expliquer par leurs spécificités économiques ou sociales.

En somme, ce type de visualisation permet d’identifier rapidement les regroupements et les oppositions entre pays, offrant une base précieuse pour des analyses comparatives plus approfondies.


```{r}
# Étape 1 : Calculer les variances des composantes principales
variances <- res$sdev^2

# Étape 2 : Calculer le pourcentage de variance expliquée
pourcentages <- variances / sum(variances) * 100

# Étape 3 : Calculer la variance expliquée cumulée
cumul <- cumsum(pourcentages)

# Étape 4 : Créer une table avec les informations organisées
variance_table <- data.frame(
  Composante = paste0("PC", seq_along(variances)),  # Étiquettes des composantes
  `Valeur propre` = round(variances, 2),
  `% Variance expliquée` = round(pourcentages, 2),
  `% Variance cumulée` = round(cumul, 2)
)

# Étape 5 : Ajuster les paramètres pour l'affichage
options(width = 100)  # Largeur de l'affichage

# Étape 6 : Afficher la table sous forme bien formatée
cat("Table des variances expliquées :\n")
print(variance_table, row.names = FALSE)

```



```{r}
#7.
variances <- res$sdev^2

# Calculer le pourcentage de variance expliquée
pourcentages <- variances / sum(variances) * 100

# Calculer la variance expliquée cumulée
cumul <- cumsum(pourcentages)

# Afficher les informations pour contrôle
cat("Valeurs propres :\n")
print(round(variances, 2))

cat("\nPourcentages de variances expliquées :\n")
print(round(pourcentages, 2))

cat("\nVariance expliquée cumulée :\n")
print(round(cumul, 2))

# Créer un graphique combiné
plot(pourcentages, type = "b", pch = 15, col = "blue",
     xlab = "Numéro de la composante principale",
     ylab = "Pourcentage de variance expliquée",
     main = "Ébouli des valeurs propres")
lines(cumul, type = "b", pch = 15, col = "red")  # Ajouter la variance cumulée

# Ajouter une légende
legend("topright", legend = c("Variance expliquée", "Variance cumulée"),
       col = c("blue", "red"), pch = 15, lty = 1)

# Ajouter une ligne verticale pour la sélection des composantes (facultatif)
abline(v = 5, col = "darkgreen", lty = 2)  # Par exemple, si 5 composantes sont retenues

```
L’ébouli des valeurs propres représente la contribution de chaque composante principale à la variance totale. Dans le graphique, la ligne bleue montre les pourcentages de variances expliquées par chaque composante, tandis que la ligne rouge illustre la variance expliquée cumulée.

En analysant la variance expliquée cumulée, les cinq premières composantes principales expliquent environ 77 % de la variance totale. Cela justifie le choix de retenir les cinq premières composantes pour une analyse approfondie, car elles capturent l'essentiel de l'information tout en réduisant la dimensionnalité des données. Les composantes suivantes apportent une contribution marginale et peuvent être négligées pour simplifier l’interprétation.

Le critère de l’éboulis (coudée visible dans la ligne bleue après la cinquième composante) renforce également cette décision. Ainsi, la sélection des cinq premières composantes est justifiée à la fois par la proportion de variance expliquée et par la méthode visuelle.









```{r, fig.width=10, fig.height=8}
# 8
# Créer le biplot avec des couleurs et des tailles ajustées
biplot(res, scale = 0, 
       main = "Biplot des projections des pays et des variables",
       cex = 0.8,  # Taille des points et flèches
       col = c("blue", "red"))
```
Le biplot illustre simultanément les projections des pays, identifiés par des numéros en bleu, et des variables initiales, représentées par des flèches rouges, dans le plan formé par les deux premières composantes principales (PC1 et PC2). Cette représentation permet d’observer les regroupements de pays ayant des profils similaires ainsi que l’influence des variables sur les composantes principales. Les flèches rouges indiquent la direction et l’intensité des variables : plus la flèche est longue, plus la contribution de la variable à la composante principale est importante. On remarque que Renewable.energy, Greenhouse.gas.emissions et Youth.population influencent fortement le PC1, tandis que des variables comme People.at.risk.of.poverty.or.exclusion et Youth.unemployment.rate ont un impact plus prononcé sur le PC2.

Les pays proches sur le graphique ont des caractéristiques comparables. Par exemple, la Norvège (29) et l’Islande (28), situées à l’extrémité droite, se démarquent par leurs valeurs élevées de Renewable.energy, reflétant leur forte utilisation des énergies renouvelables. En revanche, la Grèce (12) et l’Espagne (26), situées à l’opposé dans le plan factoriel, présentent des spécificités économiques différentes. On observe également un regroupement central formé par la Pologne (21), la Slovénie (25), la Suède (27) et Malte (19), suggérant des similitudes dans leurs profils globaux.

Ce biplot facilite l’analyse des similarités et divergences entre les pays et met en évidence les variables expliquant ces différences. Il constitue ainsi un outil essentiel pour interpréter les relations complexes au sein des données multidimensionnelles.




Bien que le plan formé par les composantes principales PC1 et PC2 capture la majeure partie de la variance des données, il ne représente pas nécessairement toutes les informations de manière optimale pour chaque variable ou individu. En effet, certaines variables ou certains pays pourraient être mieux expliqués dans d’autres plans factoriels. Il est donc pertinent d’explorer des plans complémentaires, tels que PC2 vs PC3, pour obtenir une vision plus exhaustive et détaillée des relations entre les variables et les pays.


```{r, fig.width=8, fig.height=10}
#  9 
# Plan PC2 vs PC3
biplot(res, choices = c(2, 3), scale = 0, 
       main = "Biplot des projections des pays et des variables (PC2 vs PC3)",
       cex = 0.8,  
       col = c("blue", "red"))  

```


Le biplot montre simultanément les projections des pays et des variables dans le plan formé par les composantes principales PC2 et PC3. Ce plan permet d’explorer des informations supplémentaires qui n’étaient pas totalement visibles dans le premier plan (PC1 vs PC2).

Les variables représentées par les flèches rouges indiquent leur contribution au plan PC2 vs PC3. On remarque que certaines variables, comme Renewable Energy et Youth Population, ont une forte contribution dans la direction de PC3. De même, des variables comme Gender Pay Gap et Inflation Rate influencent davantage le PC2.

Du côté des pays (points bleus numérotés), on observe que :

Les pays 28 (Islande) et 29 (Norvège) se distinguent encore une fois dans la direction de Renewable.energy, reflétant leur forte proportion d’énergie renouvelable dans la consommation totale. Les pays 21 (Pologne) et 13 (Hongrie) sont projetés dans la direction de Inflation.rate et Gender.pay.gap, indiquant des caractéristiques liées à ces indicateurs économiques.




```{r, fig.width=8, fig.height=10}
# 9.
# Plan PC3 vs PC4
biplot(res, choices = c(3, 4), scale = 0, 
       main = "Biplot des projections des pays et des variables (PC3 vs PC4)",
       cex = 0.8,  # Taille des points et flèches
       col = c("blue", "red"))  
```
Sur le second plan factoriel (PC3 vs PC4), certaines variables se distinguent par leur forte influence. On observe notamment que Energy.imports.dependency et Renewable.energy présentent des projections marquées dans des directions opposées. Cela traduit une relation inverse entre ces deux variables : les pays ayant une forte dépendance aux importations d’énergie tendent à utiliser moins d’énergies renouvelables, et vice versa.

Les variables Population et First.time.asylum.applicants se projettent dans des directions similaires, indiquant une corrélation . Cela peut refléter une tendance selon laquelle les pays ayant une population élevée reçoivent davantage de premières demandes d’asile. Une relation similaire est observée entre les varibles infliation.rates et Electicité.Prices, indiquant leur compatitibilité à évoluer dans le meme sens.



Au niveau des pays, on observe que le pays 11 (Allemagne)se distingue nettement sur l’axe PC3, en bas à gauche, par son éloignement des autres. Cela reflète des caractéristiques uniques par rapport aux autres nations. Les pays 29 (Norvège) et 28 (Islande) restent toujours associés à la variable Renewable.energy sur l'axe PC3, ce qui souligne leur forte indépendance énergétique liée à une faible dépendance aux importations d’énergie.

Le plan PC2 vs PC3 et PC3 vs PC4 consolident et révèlent des informations supplémentaires sur les relations entre les pays, qui étaient moins visibles dans le plan précédent. Ce type d’analyse permet ainsi de compléter la compréhension des relations complexes entre les variables et les pays européens.

Ces analyses mettent en lumière les interactions complexes entre les variables et les pays, offrant une meilleure compréhension des dynamiques sous-jacentes et identifiant les facteurs différenciant certains pays.





```{r, fig.width=8, fig.height=10}
#  10. Déterminez quelles sont les variables les mieux représentées par le premier plan factoriel.
# Étape 1 : Extraire les loadings des composantes principales
loadings <- res$rotation

# Étape 2 : Calculer le cos² pour le plan PC1-PC2
cos2_PC1_PC2 <- rowSums(loadings[, 1:2]^2)  # Somme des carrés des charges sur PC1 et PC2

# Étape 3 : Créer une table avec les cos² et les variables associées
cos2_table <- data.frame(
  Variable = rownames(loadings),          # Noms des variables
  Cos2_PC1_PC2 = round(cos2_PC1_PC2, 2)   # Valeurs arrondies des cos²
)

# Étape 4 : Vérifier que la colonne Cos2_PC1_PC2 est bien un vecteur numérique
cos2_table$Cos2_PC1_PC2 <- as.numeric(cos2_table$Cos2_PC1_PC2)

# Étape 5 : Trier les variables par ordre décroissant de cos²
cos2_table <- cos2_table[order(cos2_table$Cos2_PC1_PC2, decreasing = TRUE), ]

# Étape 6 : Afficher la table triée
cat("Cos² des variables sur le plan PC1-PC2 (par ordre de qualité) :\n")
print(cos2_table, row.names = FALSE)


```



Les cos² indiquent la qualité de la représentation des variables sur le premier plan factoriel (PC1-PC2). Plus le cos² est élevé, meilleure est la représentation de la variable sur ce plan. Les variables les mieux représentées incluent Minimum.wage, GDP.per.capita, et Youth.population, avec des cos² respectifs de 0.23, 0.21 et 0.16. Ces variables jouent donc un rôle clé dans la structuration de ce plan factoriel.

En revanche, des variables comme Gender.pay.gap et Early.school.leavers ont des cos² très faibles (0.05 et 0.00), indiquant qu'elles ne sont pas bien représentées sur ce plan. Cela signifie que leur contribution à l'inertie totale du plan PC1-PC2 est limitée, et qu'elles pourraient être mieux représentées sur d'autres plans factoriels.

Ces résultats permettent de se concentrer sur les variables dominantes pour analyser les premières composantes principales et comprendre leur impact sur la structuration des individus et des variables.



```{r, fig.width=10, fig.height=7}
# 11
# Étape 1 : Extraire les scores des individus
scores <- res$x  # Les coordonnées des individus dans le nouvel espace

# Étape 2 : Extraire les variances des composantes principales (valeurs propres)
variances <- res$sdev^2  # Variances associées à chaque composante principale

# Étape 3 : Calculer les contributions des individus sur chaque composante
# Contribution = (scores^2) / (variance de la composante)
contributions <- sweep(scores^2, 2, variances, "/")

# Étape 4 : Ajuster les paramètres pour l'affichage
options(width = 150)  # Ajuste la largeur pour éviter les retours à la ligne

# Étape 5 : Afficher les contributions des individus sous forme de tableau
contributions_table <- data.frame(Individu = seq_len(nrow(contributions)),
                                  round(contributions, 2))  # Arrondir les valeurs pour lisibilité

cat("Contributions des individus sur chaque composante principale :\n")
print(contributions_table, row.names = FALSE)

```
L’analyse des contributions des individus aux composantes principales a permis de mettre en évidence plusieurs aspects intéressants. Tout d’abord, les composantes principales les plus importantes, notamment PC1, PC2, PC3 et PC4, capturent la majeure partie de la variance totale des données. Les contributions élevées sur ces composantes montrent les individus qui influencent fortement la structure globale de l’espace factoriel. Par exemple, l’individu 11 (Allemagne) se distingue particulièrement sur PC3 (5.35), PC5 (9.89) et PC15 (3.44), tandis que l'individu 18 (Luxembourg) se démarque sur PC1 (4.95) et sur PC5 (3.90), de même que l'individu 19 (Malte) avec une valeur remarquable sur PC7 (11.17).

L'individu 28 (Islande) se démarque sur PC3 (3.41) et sur PC10 (3.40). L'individu 25 (Slovénie) se distingue également sur PC13 (7.63).

Les contributions totales révèlent que certains individus, comme 11 (Allemagne), 18 (Luxembourg) et 28 (Islande), participent de manière significative à la variance expliquée sur plusieurs axes, ce qui explique leur rôle important dans l’analyse. D’autres individus, bien que moins marquants sur les composantes principales initiales, se révèlent essentiels sur des axes secondaires. Par exemple, l’individu 23 (Roumanie) a une forte contribution sur PC5, et l’individu 19 (Malte) se distingue clairement sur PC7. Ainsi, si PC7 était utilisé dans l'un des plans d'analyse, il serait tout à fait pertinent de refaire cette analyse sans l'individu 19 (Malte), en raison de sa forte contribution (11.17), c'est-à-dire en le supprimant temporairement de l’analyse.

La suppression d’un individu dans une analyse en ACP peut se justifier si cet individu a une contribution anormalement élevée sur une ou plusieurs composantes principales, ce qui peut indiquer qu’il exerce une influence disproportionnée sur les résultats globaux (outlier). Cela peut biaiser l’interprétation des axes.

Cette répartition des contributions montre que tous les individus jouent un rôle dans la construction des composantes principales, aucun ne pouvant être considéré comme négligeable ou trop influent sur les axes utilisés dans les plans (PC1, PC2, PC3, PC4).

Cela signifie qu’il n’est pas nécessaire de retirer des individus de l’analyse de manière définitive, car chacun contribue de manière significative à l’explication de la variance totale.

Les individus ayant des contributions élevées sur certaines composantes principales indiquent des particularités ou des caractéristiques spécifiques qui les différencient des autres, tandis que ceux ayant une contribution plus homogène sur l’ensemble des composantes montrent une participation équilibrée dans l’analyse.

Avant de passer à l’ordre des contributions, cette analyse globale offre déjà une vue d’ensemble des rôles joués par chaque individu dans la construction des composantes principales et dans l’explication de la variance totale des données.


```{r, fig.width=10, fig.height=7}
# Étape 5 : Calcul des contributions totales par individu (somme sur toutes les composantes)
contributions_totales <- rowSums(contributions)

# Étape 6 : Trier les contributions totales de façon décroissante
contributions_totales_table <- data.frame(Individu = seq_len(nrow(scores)),
                                          Contribution_Totale = round(contributions_totales, 2))
contributions_totales_table <- contributions_totales_table[order(-contributions_totales_table$Contribution_Totale), ]

# Étape 7 : Afficher les contributions totales triées sous forme de tableau
cat("\nContributions totales par individu (classées par ordre décroissant) :\n")
print(contributions_totales_table, row.names = FALSE)

```




```{r, fig.width=10, fig.height=7}
#11..

seuil <- 1 / nrow(scores) 
individus_faibles <- contributions_totales_table$Individu[contributions_totales < seuil]

# Étape 8 : Afficher les individus ayant une contribution faible
if (length(individus_faibles) == 0) {
 #  cat("\nAucun individu n'a une contribution faible. Il n'est pas nécessaire d'éliminer des individus.\n")
} else {
  cat("\nIndividus ayant une contribution faible (en dessous du seuil) :\n")
  print(individus_faibles)
}
```
L’analyse globale des contributions montre que les individus 11, 28 et 18 se démarquent par des contributions totales particulièrement élevées, respectivement 25.03 %, 23.55 % et 21.50 %. Cela signifie qu’ils jouent un rôle majeur dans l’explication de la variance globale des données sur l’ensemble des composantes principales.

Les individus 25, 23, 12 et 26 suivent de près, avec des contributions allant de 18.42 % à 19.12 %. Ces valeurs confirment leur importance relative dans l’analyse, même s’ils ne dominent pas autant que les trois premiers. Ces individus influencent fortement plusieurs axes, ce qui renforce leur pertinence dans l’espace factoriel.

En revanche, les individus 1, 7 et 24 affichent les contributions les plus faibles, respectivement 9.50 %, 9.72 % et 9.42 %. Bien que ces valeurs soient les plus basses, elles restent significativement supérieures au seuil minimal de 3.33 %, ce qui confirme que tous les individus participent de manière notable à l’explication de la variance totale.

Cette hiérarchisation des individus permet d’identifier ceux qui contribuent le plus à l’explication des données et ceux dont l’influence est plus modérée. Elle met en lumière les individus clés dans l’interprétation des résultats de l’analyse en composantes principales (ACP) et justifie l’inclusion de tous les individus dans l’étude.

La suppression d'un individu reste une décision contextuelle : elle dépend du domaine d’application et de l’objectif de l’analyse.

En définitive, aucun individu ne présente une valeur qui s’éloigne significativement de la moyenne, surtout sur les axes utilisés pour les plans de l’analyse (PC1, PC2, PC3, PC4), d’où le choix de ne supprimer aucun individu.


```{r, fig.width=14, fig.height=10}
# 12 

# Étape 1 : Extraire les scores
coord <- res$x  # Scores des individus

# Étape 2 : Ajouter les noms des pays
tmp <- read.csv("data/euro.csv", header = TRUE, sep = ";")  # Charger les noms
rownames(coord) <- tmp[, 1]

# Étape 3 : Créer le graphique
plot(coord[, 1], coord[, 2], 
     xlab = "PC1 (Composante principale 1)", 
     ylab = "PC2 (Composante principale 2)", 
     main = "Projection des individus sur le plan PC1-PC2", 
     pch = 20, col = "blue")

# Ajouter les noms des individus
text(coord[, 1], coord[, 2], labels = rownames(coord), pos = 4, cex = 0.8)
```
La projection des individus sur les composantes principales (PC1 et PC2) montre des regroupements qui correspondent globalement aux similarités socio-économiques attendues :

 On peut remarquer un regroupement de certains pays du nord, situés en haut à droite, comme l’Islande, la Norvège, le Danemark et l’Irlande, qui contrastent avec des pays du sud comme l’Espagne, l’Italie et la Grèce en bas à gauche. Ces proximités et éloignements, ou encore ces similarités et dissimilarités, s’expliquent du point de vue des variables socio-économiques considérées. Bien qu’il puisse exister une certaine corrélation entre la proximité des pays et leur situation géographique, cette relation n’est pas systématique : on observe, par exemple, la Suisse parmi les pays du nord alors qu’elle ne fait pas partie de cette région. De même, certains pays du nord se rapprochent de pays appartenant à d’autres zones géographiques.C'est la cas de la la Suède  juste au desssus du centre. 

Au centre du graphique, on observe un regroupement de pays comme la Pologne, la Suède, Malte et la Slovénie, qui partagent des caractéristiques socio-économiques similaires.

En haut à gauche, on trouve particulièrement des pays de l'Est comme la Bulgarie, la Hongrie et la Roumanie, qui sont diamétralement opposés à des pays tels que l’Allemagne et la Belgique, situés en bas à droite.

*Conclusion* 
Cette étude en analyse en composantes principales (ACP) a permis de réduire la dimensionnalité des données tout en conservant l'essentiel de l'information. Les résultats obtenus, tels que les projections des pays sur les composantes principales et l'éboulis des valeurs propres, ont révélé des regroupements significatifs et des similarités  entre les pays en fonction de leurs caractéristiques socio-économiques. Ces visualisations offrent une vue claire des relations entre les variables et des différences structurelles entre les pays, facilitant ainsi une interprétation plus approfondie. Cette analyse constitue une base solide pour explorer des méthodes complémentaires, telles que le partitionnement, afin de segmenter davantage les pays en groupes homogènes.

```{r, fig.width=12, fig.height=10}
# TP2 ****************
```








```{r}
# 1  

# Matrice de dissimilarité Euclidienne (non normalisée)
dissimilarity_euclidean <- as.matrix(dist(euro_data, method = "euclidean"))

# Normaliser les données
euro_data_normalized <- scale(euro_data)

# Matrice de dissimilarité Euclidienne (normalisée)
dissimilarity_reduced <- as.matrix(dist(euro_data_normalized, method = "euclidean"))

# Fonction pour afficher une matrice par blocs de colonnes
afficher_matrice_par_blocs <- function(mat, bloc_size = 10, titre = "Matrice") {
  n <- ncol(mat)  # Nombre de colonnes total
  for (start_col in seq(1, n, by = bloc_size)) {
    end_col <- min(start_col + bloc_size - 1, n)  # Déterminer la fin du bloc
    cat("\n", titre, "(colonnes", start_col, "à", end_col, "):\n")
    print(round(mat[, start_col:end_col], 2))
  }
}

# Afficher la matrice de dissimilarité Euclidienne non normalisée par blocs de 9 colonnes
afficher_matrice_par_blocs(dissimilarity_euclidean, bloc_size = 9, 
                           titre = "Matrice de dissimilarité Euclidienne (non normalisée)")

# Afficher la matrice de dissimilarité Euclidienne normalisée par blocs de 15 colonnes
afficher_matrice_par_blocs(dissimilarity_reduced, bloc_size = 15, 
                           titre = "Matrice de dissimilarité Euclidienne (normalisée)")



```





```{r, fig.width=14, fig.height=10}
# Question 1 suite 
# CAH avec la matrice non normalisée
cah_single_euclidean <- hclust(dist(euro_data, method = "euclidean"), method = "single")

# CAH avec la matrice normalisée
cah_single_reduced <- hclust(dist(euro_data_normalized, method = "euclidean"), method = "single")

# Dendrogramme pour les données non normalisées
plot(cah_single_euclidean, 
     main = "Dendrogramme (Euclidienne, non normalisée)", 
     xlab = "Pays", sub = "", cex = 0.8)

# Dendrogramme pour les données normalisées
plot(cah_single_reduced, 
     main = "Dendrogramme (Euclidienne, normalisée)", 
     xlab = "Pays", sub = "", cex = 0.8)


```
Les dendrogrammes obtenus à partir des matrices de dissimilarité Euclidienne normalisée et non normalisée mettent en évidence des différences dans les regroupements des pays. Avec la matrice normalisée, les échelles des variables sont équilibrées, ce qui permet une contribution équitable de chaque caractéristique aux regroupements.

Cela se traduit par une structure de classification où les similarités relatives entre les pays sont mieux prises en compte. En revanche, la matrice non normalisée amplifie l'influence des variables à grande échelle, ce qui peut biaiser les regroupements en privilégiant certaines caractéristiques au détriment d'autres.

Les fusions à des hauteurs plus élevées dans le dendrogramme non normalisé indiquent des dissimilarités globales plus marquées. Cette comparaison souligne l'importance de la normalisation pour éviter les biais et obtenir des regroupements reflétant plus fidèlement les similarités relatives entre les pays.

Le dendrogramme avec normalisation des données est davantage aligné avec les résultats obtenus lors de l'ACP, notamment sur les plans de projection, car on peut remarquer que les individus 21 (Pologne) et 25 (Slovénie) appartiennent au même cluster, tout comme le regroupement des individus 28 (Islande) et 29 (Norvège), comme observé lors de l’étude sur l’ACP.

En revanche, dans le dendrogramme basé sur les données non normalisées, les individus 28 (Islande) et 29 (Norvège) ne se trouvent pas dans le même cluster, bien que ces deux individus, qui se distinguent, n’aient jamais été éloignés l’un de l’autre dans l’ensemble des plans de l’ACP.



```{r}
# Question 2 
#2. Représentez le dendrogramme ainsi que la “hauteur” (attribut height) en fonction du nombre de classes. Que
#représente la “hauteur” ici ? Ou couperiez-vous le dendrogramme ?
# Récupérer les hauteurs des fusions
heights_euclidean <- sort(cah_single_euclidean$height, decreasing = TRUE)
heights_reduced <- sort(cah_single_reduced$height, decreasing = TRUE)

# Courbe des hauteurs pour la matrice non normalisée
plot(1:length(heights_euclidean), heights_euclidean, 
     type = "b", col = "blue", pch = 20,
     xlab = "Nombre de classes", 
     ylab = "Hauteur", 
     main = "Hauteur en fonction du nombre de classes (Euclidienne, non normalisée))")

# Courbe des hauteurs pour la matrice normalisée
plot(1:length(heights_reduced), heights_reduced, 
     type = "b", col = "red", pch = 20,
     xlab = "Nombre de classes", 
     ylab = "Hauteur", 
     main = "Hauteur en fonction du nombre classes (Euclidienne,normalisée)")


```
Les deux graphiques montrent la relation entre le nombre de classes et la hauteur des fusions dans le dendrogramme pour des matrices de dissimilarité euclidiennes, normalisées et non normalisées. La hauteur correspond à la dissimilarité entre les clusters au moment de leur fusion.

Dans le cas de la matrice normalisée, les contributions des différentes variables sont équilibrées, ce qui permet d’obtenir des regroupements plus représentatifs de la structure globale des données. En revanche, avec la matrice non normalisée, certaines variables peuvent dominer les regroupements en raison de leurs échelles différentes, ce qui peut biaiser l’interprétation.

Découpage du dendrogramme :
Le point de découpe optimal dépend du contexte de l’analyse, mais il est souvent déterminé en identifiant une hauteur au-delà de laquelle les fusions deviennent moins significatives (c’est-à-dire lorsqu’un "saut" important dans la hauteur des fusions est observé).

  Pour le dendrogramme basé sur la matrice normalisée, un découpage à environ 3 ou 4 clusters pourrait être justifié, car les différences de hauteur sont notables à ces niveaux.
  Pour le dendrogramme non normalisé, un découpage similaire peut être envisagé, mais avec prudence, car les fusions pourraient être influencées par des variables dominantes.







```{r, fig.width=14, fig.height=10}

# Q3
# Nettoyage des données
euro_data_clean <- na.omit(euro_data)  
euro_data_clean <- euro_data_clean[is.finite(rowSums(euro_data_clean)), ] 

# Recalculer le dendrogramme pour les données nettoyées
cah_clean <- hclust(dist(euro_data_clean, method = "euclidean"), method = "single")
classes <- cutree(cah_clean, k = 4)

# Calcul des centres de gravité
centers <- aggregate(. ~ Classe, data = data.frame(Classe = classes, euro_data_clean), FUN = mean)

# Calcul des inerties intra-classes
inertia <- sapply(unique(classes), function(k) {
  members <- euro_data_clean[classes == k, ]
  center <- colMeans(members)
  sum(rowSums((members - center)^2))
})

# Assigner des noms aux inerties
names(inertia) <- paste("Classe", unique(classes))

# Afficher les résultats
cat("Centres de gravité des classes :\n")
print(centers)

cat("\nInerties intra-classes :\n")
print(inertia)

# Ajouter les classes aux données pour visualisation
euro_data_with_classes <- euro_data_clean
euro_data_with_classes$Classe <- as.factor(classes)

# Afficher les premières lignes des données avec classes
cat("\nAperçu des données avec les classes :\n")
print(head(euro_data_with_classes))


```
Les résultats montrent que les classes regroupent des pays présentant des caractéristiques similaires en termes de démographie, développement économique, et gestion des ressources. Par exemple :

Classe 3 : Cette classe se distingue par des valeurs homogènes et élevées en termes de PIB par habitant et de développement économique, représentant ainsi des économies stables et avancées.

Classe 2 : Elle regroupe des pays présentant des défis économiques importants, avec une forte variabilité interne, notamment au niveau des indicateurs sociaux et économiques, comme les taux de chômage et les niveaux de revenu.

Les centres de gravité permettent de dégager des profils moyens pour chaque classe, tandis que les inerties intra-classes fournissent une mesure quantitative de leur homogénéité. On remarque que la classe 3 présente une inertie intra-classe nulle, ce qui signifie que les pays regroupés dans cette classe ont des caractéristiques très proches, donc peu de dispersion autour de leur centre de gravité. À l’opposé, la classe 1 montre une inertie intra-classe très élevée, indiquant une grande variabilité entre les pays qui la composent.

Ce découpage met en évidence l’importance des variables économiques et environnementales dans la formation des classes, notamment des indicateurs comme le PIB par habitant, les prix de l’électricité et les émissions de gaz à effet de serre, qui semblent jouer un rôle clé dans la différenciation des groupes.

En résumé, les centres de gravité offrent une description claire des caractéristiques dominantes de chaque classe, et les inerties intra-classes permettent de mesurer leur homogénéité. Cette classification met ainsi en relief les disparités socio-économiques et environnementales entre les pays européens.





```{r, fig.width=14, fig.height=10}
# Question 4 
# Classification ascendante hiérarchique avec le critère de Ward
cah_ward <- hclust(dist(euro_data_normalized, method = "euclidean"), method = "ward.D2")

# Représenter le dendrogramme
plot(cah_ward, 
     main = "Dendrogramme (Critère de Ward, Euclidienne, normalisée)", 
     xlab = "Pays", sub = "", cex = 0.8)
par(mfrow = c(1, 2))  # Afficher les deux dendrogrammes côte à côte

# Dendrogramme avec le saut minimum
plot(cah_single_reduced, 
     main = "Dendrogramme (Saut minimum)", 
     xlab = "Pays", sub = "", cex = 0.8)

# Dendrogramme avec Ward
plot(cah_ward, 
     main = "Dendrogramme (Critère de Ward)", 
     xlab = "Pays", sub = "", cex = 0.8)

par(mfrow = c(1, 1))  # Réinitialiser l'affichage


```
La classification réalisée avec le critère de Ward met en évidence des regroupements plus homogènes par rapport à la méthode du saut minimum. En effet, le critère de Ward minimise la variance intra-classe à chaque étape, ce qui aboutit à des groupes plus équilibrés en termes de similarités internes. Les fusions observées dans le dendrogramme de Ward se produisent de manière progressive et uniforme, illustrant une intégration cohérente des pays dans des groupes.

En comparaison, la classification avec le saut minimum privilégie les regroupements basés uniquement sur la proximité immédiate entre les éléments, ce qui peut conduire à des groupes moins équilibrés. Les fusions dans ce cas se produisent à des hauteurs plus irrégulières, reflétant une plus grande hétérogénéité des groupes finaux. Cela peut être utile pour explorer des proximités locales mais offre moins d’interprétabilité globale.

Dans le cas du critère de Ward, les pays sont regroupés selon des caractéristiques économiques et sociales communes, ce qui permet d’identifier des clusters cohérents et interprétables. Par exemple, les pays ayant des niveaux similaires de PIB par habitant ou d'émissions de gaz à effet de serre tendent à être regroupés dans la même classe. En revanche, avec le saut minimum, les regroupements peuvent être influencés par des proximités géographiques ou d’autres caractéristiques ponctuelles.

En conclusion, le critère de Ward se révèle particulièrement adapté pour une analyse visant à identifier des structures globales et homogènes dans les données, tandis que le saut minimum peut être utile pour explorer des relations locales ou des proximités immédiates. Les deux approches offrent des perspectives complémentaires sur les regroupements des pays.




```{r}

# 5 
# Vérifier les NA ou NaN dans les données normalisées
cat("Y a-t-il des NA/NaN dans les données ?\n")
print(any(is.na(euro_data_normalized)))

# Si des NA sont présents, afficher leur localisation
if (any(is.na(euro_data_normalized))) {
  cat("Position des NA/NaN :\n")
  print(which(is.na(euro_data_normalized), arr.ind = TRUE))
  euro_data_normalized <- apply(euro_data_normalized, 2, function(x) {
  ifelse(is.na(x), mean(x, na.rm = TRUE), x)
})
print(any(is.na(euro_data_normalized)))
}
```





```{r}

# 5. 
# Fixer le nombre de classes
k <- 4

# Appliquer k-means
set.seed(42)  # Fixer la graine pour rendre les résultats reproductibles
kmeans_result <- kmeans(euro_data_normalized, centers = k, nstart = 10)

# Afficher les résultats
cat("Classes affectées par k-means :\n")
print(kmeans_result$cluster)

cat("\nCentres des classes (affichage par groupes de 4 variables) :\n")

# Affichage par groupes de 4 variables
print(round(kmeans_result$centers[, 1:4], 2), row.names = FALSE)
cat("\n")
print(round(kmeans_result$centers[, 5:8], 2), row.names = FALSE)
cat("\n")
print(round(kmeans_result$centers[, 9:12], 2), row.names = FALSE)
cat("\n")
print(round(kmeans_result$centers[, 13:16], 2), row.names = FALSE)

cat("\nInertie intra-classe totale :\n")
print(round(kmeans_result$tot.withinss, 2))


```
L'algorithme des k-means, appliqué avec k=4 classes, a permis de regrouper les pays en fonction de leurs similarités sur les variables normalisées. Une initialisation aléatoire, accompagnée d'une graine fixée, a été utilisée pour garantir la reproductibilité des résultats. Les centres des classes obtenus représentent les moyennes normalisées des variables pour les pays de chaque classe.

La courbe d'inertie expliquée montre une amélioration continue lorsque k augmente, traduisant une meilleure distinction entre les groupes. Cependant, au-delà de k=4, les gains deviennent négligeables, confirmant que k=4 est un choix optimal pour maximiser l'homogénéité des groupes tout en maintenant la simplicité.

L'algorithme k-means se distingue des méthodes hiérarchiques (comme Ward ou le saut minimum) par sa capacité à minimiser directement l'inertie intra-classe. Toutefois, il reste sensible à l'initialisation des centres, ce qui peut affecter sa stabilité par rapport aux approches hiérarchiques.



```{r}

```



```{r}
#6
# Initialiser les variables
max_k <- 10  # Tester jusqu'à 10 classes
inertie_totale <- sum(scale(euro_data_normalized, center = TRUE, scale = FALSE)^2)
inertie_intra <- numeric(max_k)
inertie_expliquee <- numeric(max_k)

# Calculer l'inertie intra-classe pour chaque k
for (k in 1:max_k) {
  set.seed(42)  # Graine pour reproductibilité
  kmeans_result <- kmeans(euro_data_normalized, centers = k, nstart = 10)
  inertie_intra[k] <- kmeans_result$tot.withinss
  inertie_expliquee[k] <- 1 - (inertie_intra[k] / inertie_totale)
}

# Détection manuelle du coude
diff_inertie <- diff(inertie_expliquee)  # Calculer les différences successives
optimal_k <- which.max(diff_inertie < 0.05) + 1  # Trouver le premier petit gain marginal

# Afficher les résultats
cat("Nombre optimal de classes selon la méthode du coude :", optimal_k, "\n")

# Tracer la courbe de l'inertie expliquée
plot(1:max_k, inertie_expliquee, type = "b", pch = 20, col = "blue",
     xlab = "Nombre de classes (k)", ylab = "Inertie expliquée (%)",
     main = "Inertie expliquée en fonction du nombre de classes")
abline(v = optimal_k, col = "red", lty = 2)  # Marquer le coude sur la courbe


```
Nous avons appliqué l'algorithme des kk-means sur les données normalisées en faisant varier le nombre de classes (k) de 1 à 10, et nous avons calculé l'inertie expliquée pour chaque valeur de k.
Affichage de l'inertie expliquée :

La courbe ci-dessus montre l'inertie expliquée en fonction du nombre de classes (k). L'inertie expliquée augmente avec k, ce qui reflète une meilleure capacité du modèle à regrouper les données. Cependant, les gains d'inertie deviennent de plus en plus faibles à partir d'un certain k, un phénomène communément appelé "le coude de la courbe".
Détection automatique du coude :

Pour identifier le nombre optimal de classes, nous avons utilisé un critère basé sur les variations marginales de l'inertie expliquée (Δ inertie). En comparant les gains d'inertie successive, le "coude" a été détecté pour k=8k=8 (ligne rouge sur le graphique), ce qui correspond à une valeur au-delà de laquelle les gains deviennent négligeables.
Justification du critère :

Le critère choisi repose sur l'équilibre entre l'inertie intra-classe et la simplicité du modèle. En augmentant k, l'inertie intra-classe diminue, mais une valeur trop élevée de k conduit à des classes moins significatives et moins généralisables. k=8 permet donc de maximiser l'homogénéité des classes tout en maintenant une complexité raisonnable.
Comparaison avec d'autres algorithmes :

En comparant ces résultats avec les classifications obtenues par les méthodes hiérarchiques (Ward, saut minimum), nous observons que :

  Les classifications obtenues par k-means sont différentes car cet algorithme minimise directement l'inertie intra-classe et dépend fortement de l'initialisation des centres.
  Les méthodes hiérarchiques, comme Ward, sont moins sensibles à l'initialisation mais peuvent produire des groupes légèrement différents en raison de leur approche ascendante.

Conclusion :

L'algorithme des kk-means avec k=8 est un choix optimal selon notre critère basé sur le coude de la courbe. Cependant, les résultats diffèrent légèrement selon les algorithmes utilisés, en raison des hypothèses et des mécanismes spécifiques à chaque méthode. Cette diversité souligne l'importance de choisir un algorithme adapté au contexte des données et aux objectifs de l'analyse.

```{r}

#7
res_acp <- prcomp(euro_data_normalized, center = TRUE, scale. = TRUE)

# Résumé de l'ACP par groupes de composantes
cat("Résumé de l'ACP (PC1 à PC8) :\n")
print(summary(res_acp)$importance[, 1:8])

cat("\nRésumé de l'ACP (PC9 à PC16) :\n")
print(summary(res_acp)$importance[, 9:16])

# Étape 2 : Récupérer les résultats de classification
# Fixer le nombre de classes optimal
k <- 4  

# Classes obtenues par CAH
classes_cah <- cutree(cah_single_reduced, k = k)

# Classes obtenues par k-means
classes_kmeans <- kmeans_result$cluster

# Étape 3 : Représenter les classes dans le plan factoriel
par(mfrow = c(1, 2))  # Afficher les deux graphiques côte à côte

# Représentation des classes CAH
plot(res_acp$x[, 1], res_acp$x[, 2], 
     col = classes_cah, 
     pch = 20, 
     xlab = "PC1", ylab = "PC2",
     main = "Plan factoriel avec classes CAH")

# Représentation des classes k-means
plot(res_acp$x[, 1], res_acp$x[, 2], 
     col = classes_kmeans, 
     pch = 20, 
     xlab = "PC1", ylab = "PC2",
     main = "Plan factoriel avec classes k-means")

par(mfrow = c(1, 1))  # Réinitialiser l'affichage


```


L’analyse en composantes principales a été réalisée sur les données normalisées afin de réduire la dimensionnalité et de visualiser les classes obtenues dans un plan factoriel. Les deux premières composantes principales (PC1 et PC2) expliquent ensemble environ 44,74 % de la variance totale des données. Cela justifie leur utilisation pour représenter les données dans un plan à deux dimensions.

Les résultats des classifications obtenues par CAH et par k-means ont été projetés sur le plan formé par les deux premières composantes principales. Concernant les classes obtenues par CAH, on observe des regroupements compacts, mais avec un certain chevauchement entre certaines observations. En revanche, les classes obtenues par k-means paraissent plus distinctes et homogènes, ce qui traduit une meilleure minimisation de l’inertie intra-classe.

La classification par k-means optimise directement la compacité des groupes, ce qui est visible dans leur projection. Cependant, elle reste sensible à l’initialisation aléatoire des centres, ce qui peut influencer les résultats. De son côté, la méthode CAH, qui repose sur des fusions hiérarchiques successives, est moins sensible à l’initialisation, mais peut produire des regroupements moins homogènes en raison de sa construction basée uniquement sur les distances entre observations.

En conclusion, les représentations graphiques combinées à l’ACP permettent de comparer visuellement les deux méthodes de classification. Bien que les deux méthodes soient globalement cohérentes, k-means semble offrir de meilleurs résultats en termes d’homogénéité des classes. Cependant, le choix de la méthode dépend des objectifs de l’étude : k-means convient mieux pour obtenir des groupes compacts, tandis que CAH peut être plus adapté lorsqu’une hiérarchie des regroupements est recherchée.




```{r}
# Créer un data frame coord_acp en combinant les coordonnées factorielles et les classes
coord_acp <- data.frame(PC1 = res_acp$x[, 1], 
                        PC2 = res_acp$x[, 2], 
                        Classe_CAH = classes_cah)

```


```{r}
zone_restante <- coord_acp[coord_acp$PC1 > -1 & coord_acp$PC1 < 1 & 
                           coord_acp$PC2 > -1 & coord_acp$PC2 < 1, ]

# Afficher les pays dans la zone restreinte
cat("Pays dans la zone sélectionnée :\n")
print(zone_restante)

# Étape 2 : Représenter graphiquement la zone
plot(zone_restante$PC1, zone_restante$PC2, 
     col = zone_restante$Classe_CAH, 
     pch = 20, 
     xlab = "PC1", ylab = "PC2",
     main = "Zone restreinte avec classes CAH")

# Ajouter les noms des pays
text(zone_restante$PC1, zone_restante$PC2, 
     labels = rownames(zone_restante), pos = 4, cex = 0.8)

```



En examinant la zone restreinte choisie (où les composantes principales PC1 et PC2 se situent dans un intervalle limité), nous observons les proximités entre certains pays. Ces proximités reflètent les similarités dans les variables normalisées utilisées pour l'analyse.

Les pays identifiés dans cette zone restreinte sont : 1, 9, 19, 21, 25, et 27. Selon les classes issues des deux méthodes de classification (CAH et k-means) :

Classe CAH : Tous ces pays appartiennent à la même classe (Classe 1), indiquant une homogénéité selon cette méthode de regroupement. Cela suggère que ces pays partagent des caractéristiques communes sur l'ensemble des variables.

Classe k-means : Contrairement à CAH, les pays sont répartis dans différentes classes (3, 5, 6, et 7). Cela montre une divergence dans la manière dont k-means interprète les proximités, possiblement influencée par la minimisation de l'inertie intra-classe.

Analyse des proximités

Dans le graphique, on observe que :

  Les pays 25 et 27 sont proches sur le plan factoriel (PC1 et PC2), suggérant une similarité forte entre eux.
  Les pays 19, 21, et 25 forment un groupe légèrement dispersé mais globalement cohérent, indiquant des caractéristiques modérément similaires.
  Le pays 1 est éloigné du reste du groupe, bien qu'il fasse partie de la même classe selon CAH, ce qui pourrait indiquer une particularité spécifique sur certaines variables.

Ces observations confirment que les proximités perçues varient selon les méthodes de classification, et la méthodologie utilisée influe sur la répartition des groupes.

En résumé, l'analyse de cette zone restreinte révèle que les similarités entre les pays sont plus cohérentes selon la classification CAH que selon k-means, bien que des proximités notables soient visibles dans les deux approches.

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.




*Conclusion*

À travers cette analyse, plusieurs approches de classification ont été appliquées pour regrouper les pays selon leurs similarités sur des variables socio-économiques et environnementales. Chaque méthode, qu'il s'agisse de la Classification Ascendante Hiérarchique (CAH), de k-means, ou de l'Analyse en Composantes Principales (ACP), offre une perspective unique :

  CAH a mis en évidence des regroupements stables et homogènes, particulièrement adaptés pour explorer des hiérarchies naturelles et globales entre les pays.
  k-means a permis d'optimiser la minimisation de l'inertie intra-classe, fournissant des regroupements plus adaptés à des configurations de données complexes mais sensibles à l'initialisation.
  ACP a facilité la visualisation des proximités entre les pays dans un espace réduit, tout en révélant les dimensions principales qui expliquent la majorité de la variance des données.

Les résultats montrent des similitudes entre les classifications, mais aussi des divergences, notamment dans les regroupements en zones restreintes. Ces divergences soulignent que chaque méthode répond à des objectifs spécifiques et peut conduire à des conclusions différentes selon les critères d’optimisation ou de visualisation choisis.

En conclusion, l’analyse combinée de ces méthodes offre une vision approfondie des relations entre les pays, permettant de mieux comprendre leurs proximités et divergences. Cette complémentarité enrichit l'interprétation et montre l'importance de choisir une méthode en fonction des objectifs spécifiques de l'étude.
